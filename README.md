---

# ðŸ¦ BankModelFactory

End-to-end Machine Learning pipeline for predictive marketing in banking

---

## ðŸ“– 1. Project Overview

`BankModelFactory` is a **Data Science and MLOps project** designed to predict the likelihood that a banking client will subscribe to a **term deposit** based on marketing campaign data.

This project follows a **modular and production-grade architecture**, inspired by **Clean Architecture** and **MLOps best practices**, featuring:

* Clear separation of responsibilities (data, features, models, API)
* Full reproducibility using **Poetry**, **Hydra**, **MLflow**, and **Docker**
* Cloud-deployable **FastAPI** inference service
* Automated **CI/CD** with GitHub Actions and pre-commit hooks

---

## ðŸ’¼ 2. Business Context

Financial institutions frequently conduct **marketing campaigns** to promote banking products (like term deposits). However, these campaigns can be costly and inefficient if not properly targeted.

The dataset used in this project comes from the **[UCI Machine Learning Repository â€“ Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing)**.
Each row represents a phone contact between a bank agent and a client. The goal is to predict whether the client will subscribe (`yes`) or not (`no`) to the offer.

### ðŸ” Problem Statement

> How can we predict, *before contacting a client*, the probability that they will accept a term deposit offer â€” in order to reduce campaign costs and improve conversion rates?

---

## ðŸŽ¯ 3. Project Objective

The main goal is to build a **complete machine learning pipeline** capable of:

1. Performing exploratory analysis and data preprocessing
2. Training multiple classification algorithms (`Logistic Regression`, `Random Forest`, `CatBoost`, etc.)
3. Evaluating model performance using metrics like **ROC-AUC**, **PR-AUC**, and **F1-score**
4. Tracking experiments and results with **MLflow**
5. Deploying the final model as a **FastAPI REST API**
6. Running the entire system in the **cloud (Render, AWS ECS, or Railway)**

---

## ðŸ§  4. Solution Architecture

The solution is built around a **data-to-deployment pipeline**, following professional software engineering and MLOps principles.

---

### ðŸ§© Step 1 â€“ Data Ingestion & Preparation

* Load and clean raw marketing data
* Handle missing values and unify data types
* Remove the `duration` variable (known data leakage)
* Split the dataset into train, validation, and test sets (stratified)

ðŸ“ Code: `src/bank_model_factory/data/`

---

### âš™ï¸ Step 2 â€“ Feature Engineering

* Encode categorical variables (OneHot or CatBoost encoding)
* Impute missing values (median/mode)
* Scale numeric features (if needed)
* Implemented using Scikit-learnâ€™s `Pipeline` and `ColumnTransformer`

ðŸ“ Code: `src/bank_model_factory/features/`

---

### ðŸ§® Step 3 â€“ Modeling & Training

* Experiment with multiple models:

  * **Logistic Regression** (baseline)
  * **Random Forest**
  * **CatBoost**
  * **SVM**, **KNN**, **Naive Bayes**
  * *(optional)* **Artificial Neural Network (ANN)**
* Perform cross-validation (Stratified K-Fold)
* Log experiments and metrics using **MLflow**

ðŸ“ Code: `src/bank_model_factory/models/train.py`

---

### ðŸ“ˆ Step 4 â€“ Evaluation & Interpretation

* Evaluate model performance with:

  * ROC-AUC, PR-AUC, F1, Precision, Recall
* Generate feature importance reports (SHAP values)
* Export visual reports to the `reports/` folder

ðŸ“ Code: `src/bank_model_factory/evaluation/`

---

### ðŸŒ Step 5 â€“ API Deployment

* Expose a **REST API** using **FastAPI**
* `/predict` endpoint: takes JSON input, returns probability
* `/health` endpoint: for health checks
* Fully containerized with **Docker** for cloud deployment

ðŸ“ Code: `src/bank_model_factory/api/`

---

### â˜ï¸ Step 6 â€“ Industrialization & CI/CD

* Project packaged with **Poetry**
* Code formatting and linting enforced via **pre-commit hooks** (`black`, `ruff`, `isort`, `mypy`)
* Unit testing with **pytest** and **coverage**
* Continuous Integration using **GitHub Actions**
* Deployment-ready with **Dockerfile** and **docker-compose.yml**

---

## âš™ï¸ 5. Tech Stack

| Category            | Tools / Libraries                          |
| ------------------- | ------------------------------------------ |
| Data Processing     | Pandas, NumPy                              |
| Machine Learning    | Scikit-learn, CatBoost, PyTorch (optional) |
| Configuration       | Hydra, YAML                                |
| Experiment Tracking | MLflow                                     |
| API                 | FastAPI, Uvicorn                           |
| Packaging           | Poetry                                     |
| Code Quality        | Black, Ruff, Isort, Mypy                   |
| CI/CD               | GitHub Actions                             |
| Deployment          | Docker, Render / AWS ECS                   |

---

## ðŸ§© 6. Project Structure

```
BankModelFactory/
â”œâ”€â”€ configs/               # Hydra configuration files
â”œâ”€â”€ data/                  # Raw and processed datasets
â”œâ”€â”€ models/                # Trained models and artifacts
â”œâ”€â”€ notebooks/             # Exploratory Data Analysis
â”œâ”€â”€ reports/               # Reports and metrics
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ bank_model_factory/
â”‚   â”‚   â”œâ”€â”€ api/           # FastAPI inference service
â”‚   â”‚   â”œâ”€â”€ data/          # Data ingestion and processing
â”‚   â”‚   â”œâ”€â”€ features/      # Feature engineering
â”‚   â”‚   â”œâ”€â”€ models/        # Training and inference logic
â”‚   â”‚   â”œâ”€â”€ utils/         # Logging, config, I/O helpers
â”‚   â”‚   â””â”€â”€ cli.py         # Typer command-line interface
â”‚   â””â”€â”€ scripts/           # Pipeline launcher and API runner
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ðŸŽ¯ 7. Final Goal

> Deliver a **robust, modular, and maintainable ML system** capable of:
>
> * Managing the full lifecycle of a predictive model (from data â†’ model â†’ API â†’ cloud)
> * Serving as a **reference for modern Data Science and MLOps practices**
> * Being easily extended or deployed in real-world banking environments

---